<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebXR IMU & Acoustic Data Collector</title>
    <style>
        body {
            margin: 0;
            padding: 20px;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        button {
            padding: 12px 24px;
            font-size: 16px;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
        }

        .primary-btn {
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            color: white;
        }

        .primary-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(255, 107, 107, 0.4);
        }

        .secondary-btn {
            background: linear-gradient(45deg, #74b9ff, #0984e3);
            color: white;
        }

        .secondary-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(116, 185, 255, 0.4);
        }

        .data-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }

        .data-panel {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 12px;
            padding: 20px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .data-panel h3 {
            margin: 0 0 15px 0;
            color: #74b9ff;
            border-bottom: 2px solid #74b9ff;
            padding-bottom: 5px;
        }

        .sensor-data {
            font-family: 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.6;
        }

        .status {
            padding: 10px;
            border-radius: 6px;
            margin-bottom: 20px;
            text-align: center;
            font-weight: bold;
        }

        .status.success {
            background: rgba(46, 204, 113, 0.3);
            border: 1px solid #2ecc71;
        }

        .status.error {
            background: rgba(231, 76, 60, 0.3);
            border: 1px solid #e74c3c;
        }

        .status.warning {
            background: rgba(241, 196, 15, 0.3);
            border: 1px solid #f1c40f;
            color: #2c3e50;
        }

        .audio-visualizer {
            width: 100%;
            height: 150px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 8px;
            margin-top: 10px;
        }

        #xr-canvas {
            width: 100%;
            height: 400px;
            border-radius: 12px;
            background: rgba(0, 0, 0, 0.5);
            display: none;
        }

        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>🚀 WebXR IMU & Acoustic Data Collector</h1>
            <p>Capture motion sensor data and audio analysis in virtual/augmented reality</p>
            <div id="vr-instructions" class="data-panel" style="display: none; margin-top: 15px;">
                <h3>🎮 VR Controls</h3>
                <p><strong>Controller Controls:</strong></p>
                <ul style="text-align: left; margin: 10px 0;">
                    <li><strong>Trigger (Primary):</strong> Stop WebXR Session</li>
                    <li><strong>Grip/Secondary Trigger:</strong> Export Data</li>
                    <li><strong>X/A Button:</strong> Play Chirp (16-20kHz)</li>
                    <li><strong>Y/B Button:</strong> Play Chirp (8-23kHz)</li>
                    <li><strong>Menu Button:</strong> Toggle Audio Recording</li>
                </ul>
                <p><strong>Keyboard Shortcuts (VR Fallback):</strong></p>
                <ul style="text-align: left; margin: 10px 0;">
                    <li><strong>S:</strong> Stop WebXR Session</li>
                    <li><strong>E:</strong> Export Data</li>
                    <li><strong>P:</strong> Play Chirp (16-20kHz)</li>
                    <li><strong>P2 or 2:</strong> Play Chirp (8-23kHz)</li>
                    <li><strong>A:</strong> Toggle Audio Recording</li>
                    <li><strong>C:</strong> Clear All Data</li>
                </ul>
            </div>
        </div>

        <div id="status" class="status warning">
            Ready to start - Click "Initialize WebXR" to begin
        </div>

        <div class="controls">
            <button id="init-btn" class="primary-btn">Initialize WebXR</button>
            <button id="start-audio-btn" class="secondary-btn" disabled>Start Audio Analysis</button>
            <button id="play-chirp-btn" class="secondary-btn">🔊 Play Chirp (16-20kHz)</button>
            <button id="play-chirp2-btn" class="secondary-btn">🔊 Play Chirp (8-23kHz)</button>
            <button id="export-btn" class="secondary-btn" disabled>Export Data</button>
            <button id="github-setup-btn" class="secondary-btn">Setup GitHub</button>
            <button id="clear-btn" class="secondary-btn">Clear Data</button>
        </div>

        <div id="github-setup" class="data-panel" style="display: none; margin-bottom: 20px;">
            <h3>🔧 GitHub Configuration</h3>
            <p>To export data directly to your GitHub repository, you need a Personal Access Token:</p>
            <ol>
                <li>Go to <a href="https://github.com/settings/tokens" target="_blank">GitHub Settings → Personal access tokens</a></li>
                <li>Click "Generate new token (classic)"</li>
                <li>Give it a name like "WebXR Data Export"</li>
                <li>Select scope: <strong>repo</strong> (Full control of private repositories)</li>
                <li>Copy the generated token and paste it below:</li>
            </ol>
            <div style="margin: 15px 0;">
                <input type="password" id="github-token-input" placeholder="Paste your GitHub token here" style="width: 70%; padding: 8px; border-radius: 4px; border: 1px solid #ccc;">
                <button id="save-token-btn" class="secondary-btn" style="margin-left: 10px;">Save Token</button>
            </div>
            <p id="token-status" style="margin-top: 10px;"></p>
        </div>

        <canvas id="xr-canvas"></canvas>

        <div class="data-grid">
            <div class="data-panel">
                <h3>📱 IMU Sensor Data</h3>
                <div id="imu-data" class="sensor-data">
                    Waiting for WebXR session...
                </div>
            </div>

            <div class="data-panel">
                <h3>🔊 Audio Analysis</h3>
                <div id="audio-data" class="sensor-data">
                    Audio not started
                </div>
                <canvas id="audio-visualizer" class="audio-visualizer"></canvas>
            </div>

            <div class="data-panel">
                <h3>📊 Session Statistics</h3>
                <div id="stats-data" class="sensor-data">
                    No data collected yet
                </div>
            </div>
        </div>
    </div>

    <script>
        class WebXRSensorApp {
            constructor() {
                this.xrSession = null;
                this.xrRefSpace = null;
                this.isRunning = false;
                this.audioContext = null;
                this.microphone = null;
                this.analyser = null;
                this.dataArray = null;
                this.mediaRecorder = null;
                this.audioChunks = [];
                
                // VR Controller support
                this.controllers = [];
                this.vrButtonStates = {
                    stopPressed: false,
                    exportPressed: false,
                    lastStopPress: 0,
                    lastExportPress: 0,
                    lastChirpPlay: 0,
                    lastChirp2Play: 0
                };
                
                // Chirp playback system
                this.chirpAudio = null;
                this.chirpAudio2 = null; // Second chirp audio
                this.chirpPlaybackContext = null;
                this.chirpLoadPromise = null;
                this.chirp2LoadPromise = null; // Second chirp load promise
                
                // Raw PCM audio capture system - ALWAYS initialize as object
                this.initializeAudioSamples();
                this.audioChannelCount = 2; // Default to stereo
                this.audioWorkletNode = null;
                this.useAudioWorklet = true; // Try AudioWorklet first, fallback to ScriptProcessor
                
                // Chirp timing log for TXT file export
                this.chirpTimingLog = [];
                this.audioRecordingStartTime = null;
                
                // XR Path Logging with comprehensive metadata
                this.xrPathLog = [];
                this.xrSessionMetadata = {
                    sessionId: this.generateSessionId(),
                    referenceSpaceType: null,
                    units: 'meters',
                    handedness: 'right-handed',
                    upAxis: '+Y',
                    forwardAxis: '-Z',
                    headsetHeightM: null // Will be estimated if not using local-floor
                };
                
                // High-frequency data storage
                this.imuData = [];
                this.audioData = [];
                this.rawAudioBuffer = [];
                
                // Comprehensive XR data storage
                this.xrPoseData = [];           // Viewer pose data (position + orientation)
                this.xrViewData = [];           // Eye view data (left/right eye transforms)
                this.xrProjectionData = [];     // Projection matrix data
                this.xrRawFrameData = [];       // Raw frame data for debugging
                
                this.sessionStartTime = null;
                this.lastIMUTime = 0;
                this.imuTargetInterval = 1000 / 800; // 800Hz = 1.25ms intervals
                
                // Previous values for calculating accelerometer/gyroscope
                this.prevPosition = { x: 0, y: 0, z: 0 };
                this.prevVelocity = { x: 0, y: 0, z: 0 };
                this.prevOrientation = { x: 0, y: 0, z: 0, w: 1 };
                this.prevTime = 0;
                
                // UI elements
                this.initBtn = document.getElementById('init-btn');
                this.startAudioBtn = document.getElementById('start-audio-btn');
                this.playChirpBtn = document.getElementById('play-chirp-btn');
                this.playChirp2Btn = document.getElementById('play-chirp2-btn');
                this.exportBtn = document.getElementById('export-btn');
                this.githubSetupBtn = document.getElementById('github-setup-btn');
                this.clearBtn = document.getElementById('clear-btn');
                this.status = document.getElementById('status');
                this.canvas = document.getElementById('xr-canvas');
                this.gl = null;
                
                // Validate UI elements were found
                console.log('UI Elements found:', {
                    initBtn: !!this.initBtn,
                    startAudioBtn: !!this.startAudioBtn,
                    playChirpBtn: !!this.playChirpBtn,
                    playChirp2Btn: !!this.playChirp2Btn,
                    exportBtn: !!this.exportBtn,
                    githubSetupBtn: !!this.githubSetupBtn,
                    clearBtn: !!this.clearBtn,
                    status: !!this.status,
                    canvas: !!this.canvas
                });
                
                this.initEventListeners();
                this.checkWebXRSupport();
                
                // Final validation to ensure everything is properly set up
                this.performInitialValidation();
                
                console.log('WebXR Data Collector initialized successfully');
            }

            performInitialValidation() {
                console.log('Performing initial validation...');
                
                // Validate audio samples
                this.validateAudioSamples();
                
                // Log all critical properties
                console.log('Initial state validation:', {
                    rawAudioSamples: this.rawAudioSamples,
                    audioChannelCount: this.audioChannelCount,
                    sessionStartTime: this.sessionStartTime,
                    imuData: this.imuData,
                    audioData: this.audioData
                });
                
                // Test that all required arrays are properly initialized
                const requiredArrays = [
                    'imuData', 'audioData', 'xrPoseData', 
                    'xrViewData', 'xrProjectionData', 'xrRawFrameData'
                ];
                
                for (const arrayName of requiredArrays) {
                    if (!Array.isArray(this[arrayName])) {
                        console.error(`${arrayName} is not properly initialized as an array`);
                        this[arrayName] = [];
                    }
                }
                
                // Validate audio samples structure specifically
                if (!this.rawAudioSamples || typeof this.rawAudioSamples !== 'object') {
                    console.error('rawAudioSamples is not properly initialized as an object');
                    this.initializeAudioSamples();
                }
                
                console.log('Initial validation complete');
            }

            initEventListeners() {
                // Add debug logging to verify event listeners are being attached
                console.log('Setting up event listeners...');
                
                this.initBtn.addEventListener('click', (e) => {
                    console.log('Init button clicked!', this.isRunning);
                    e.preventDefault();
                    this.toggleWebXR();
                });
                
                this.startAudioBtn.addEventListener('click', (e) => {
                    console.log('Audio button clicked!');
                    e.preventDefault();
                    this.toggleAudio();
                });
                
                this.playChirpBtn.addEventListener('click', (e) => {
                    console.log('Chirp button clicked!');
                    e.preventDefault();
                    this.playChirp();
                });
                
                this.playChirp2Btn.addEventListener('click', (e) => {
                    console.log('Chirp2 button clicked!');
                    e.preventDefault();
                    this.playChirp2();
                });
                
                this.exportBtn.addEventListener('click', (e) => {
                    console.log('Export button clicked!');
                    e.preventDefault();
                    this.exportData();
                });
                
                this.githubSetupBtn.addEventListener('click', (e) => {
                    console.log('GitHub setup button clicked!');
                    e.preventDefault();
                    this.toggleGitHubSetup();
                });
                
                this.clearBtn.addEventListener('click', (e) => {
                    console.log('Clear button clicked!');
                    e.preventDefault();
                    this.clearData();
                });
                
                // GitHub setup event listeners
                document.getElementById('save-token-btn').addEventListener('click', () => this.saveGitHubToken());
                
                // Keyboard shortcuts for VR
                document.addEventListener('keydown', (event) => this.handleKeyboardInput(event));
                
                // Check if token is already saved
                this.checkGitHubToken();
                
                // Initialize chirp audio system
                this.initializeChirpAudio();
                
                console.log('Event listeners set up successfully');
                
                // Add test functions accessible from console
                window.testButtons = () => {
                    console.log('Testing button functionality...');
                    console.log('Button states:', {
                        initDisabled: this.initBtn.disabled,
                        exportDisabled: this.exportBtn.disabled,
                        audioDisabled: this.startAudioBtn.disabled
                    });
                    this.toggleWebXR();
                };
                
                window.debugAudioState = () => {
                    console.log('=== Audio Debug State ===');
                    console.log('audioContext:', this.audioContext);
                    console.log('audioChannelCount:', this.audioChannelCount);
                    console.log('useAudioWorklet:', this.useAudioWorklet);
                    console.log('audioWorkletNode:', this.audioWorkletNode);
                    console.log('scriptProcessor:', this.scriptProcessor);
                    
                    // Validate and check audio samples
                    const isValid = this.validateAudioSamples();
                    console.log('Audio samples validation:', isValid);
                    console.log('rawAudioSamples structure:', this.rawAudioSamples);
                    console.log('Left samples count:', this.rawAudioSamples.left.length);
                    console.log('Right samples count:', this.rawAudioSamples.right.length);
                    
                    console.log('=== End Debug ===');
                };
                
                window.testWAVExport = () => {
                    console.log('Testing stereo WAV export with synthetic audio...');
                    
                    // Generate test audio (1 second of 440Hz left, 880Hz right)
                    const sampleRate = 48000;
                    const duration = 1.0; // 1 second
                    const leftFreq = 440; // A4 note
                    const rightFreq = 880; // A5 note (octave higher)
                    const leftSamples = new Float32Array(sampleRate * duration);
                    const rightSamples = new Float32Array(sampleRate * duration);
                    
                    for (let i = 0; i < leftSamples.length; i++) {
                        leftSamples[i] = Math.sin(2 * Math.PI * leftFreq * i / sampleRate) * 0.5;
                        rightSamples[i] = Math.sin(2 * Math.PI * rightFreq * i / sampleRate) * 0.5;
                    }
                    
                    console.log('Generated test stereo samples:', leftSamples.length, 'per channel');
                    
                    // Temporarily set raw samples and export
                    const originalSamples = this.rawAudioSamples;
                    this.rawAudioSamples = {
                        left: leftSamples,
                        right: rightSamples
                    };
                    
                    // Test stereo WAV encoding
                    try {
                        const wavBuffer = this.encodeWAV(leftSamples, rightSamples, sampleRate);
                        const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
                        const filename = `test_stereo_wav_${Date.now()}.wav`;
                        
                        this.downloadFile(wavBlob, filename);
                        console.log('Test stereo WAV export successful!');
                        this.updateStatus('Test stereo WAV file exported successfully', 'success');
                    } catch (error) {
                        console.error('Test stereo WAV export failed:', error);
                        this.updateStatus('Test stereo WAV export failed: ' + error.message, 'error');
                    }
                    
                    // Restore original samples
                    this.rawAudioSamples = originalSamples;
                };
                
                window.testChirpTimingLog = () => {
                    console.log('Testing chirp timing log...');
                    
                    // Clear existing log
                    this.chirpTimingLog = [];
                    
                    // Simulate recording start
                    const recordingStart = Date.now() / 1000;
                    this.chirpTimingLog.push(`Stereo Recording Started at ${recordingStart}`);
                    
                    // Simulate chirp playbacks
                    const chirp1 = (Date.now() + 1000) / 1000;
                    const chirp2 = (Date.now() + 2000) / 1000;
                    this.chirpTimingLog.push(`FMCW Linear 16-20kHz Playback Started at ${chirp1}`);
                    this.chirpTimingLog.push(`FMCW Linear 16-20kHz Playback Started at ${chirp2}`);
                    
                    console.log('Test chirp timing log:', this.chirpTimingLog);
                    
                    // Export as TXT file
                    const txtContent = this.chirpTimingLog.join('\n');
                    const txtBlob = new Blob([txtContent], { type: 'text/plain' });
                    const filename = `test_chirp_timing_${Date.now()}.txt`;
                    
                    this.downloadFile(txtBlob, filename);
                    console.log('Test chirp timing log exported:', filename);
                    this.updateStatus('Test chirp timing log exported successfully', 'success');
                };
                
                window.testXRPathLog = () => {
                    console.log('=== XR Path Log Debug ===');
                    console.log('xrPathLog array:', this.xrPathLog);
                    console.log('xrPathLog length:', this.xrPathLog ? this.xrPathLog.length : 'undefined');
                    console.log('sessionMetadata:', this.xrSessionMetadata);
                    console.log('First few entries:', this.xrPathLog ? this.xrPathLog.slice(0, 5) : 'no data');
                    console.log('isRunning:', this.isRunning);
                    console.log('xrSession:', this.xrSession);
                    console.log('=== End Debug ===');
                };
                
                // Force enable export button for testing
                this.exportBtn.disabled = false;
                console.log('Export button force enabled for testing');
            }

            async checkWebXRSupport() {
                if (!navigator.xr) {
                    this.updateStatus('WebXR not supported on this device', 'error');
                    this.initBtn.disabled = true;
                    return;
                }

                try {
                    const isSupported = await navigator.xr.isSessionSupported('immersive-vr');
                    if (!isSupported) {
                        this.updateStatus('WebXR VR sessions not supported - will use inline mode', 'warning');
                    }
                } catch (error) {
                    this.updateStatus('Error checking WebXR support: ' + error.message, 'error');
                }
            }

            async toggleWebXR() {
                console.log('toggleWebXR called, isRunning:', this.isRunning);
                
                if (this.isRunning) {
                    console.log('Stopping WebXR session...');
                    this.stopWebXR();
                    return;
                }
                
                console.log('Starting WebXR session...');
                await this.initializeWebXR();
            }

            stopWebXR() {
                console.log('stopWebXR called, current state:', {
                    isRunning: this.isRunning,
                    hasXRSession: !!this.xrSession
                });
                
                this.isRunning = false;
                
                if (this.xrSession) {
                    console.log('Ending XR session...');
                    this.xrSession.end();
                } else {
                    console.log('No XR session to end');
                }
                
                this.onSessionEnd();
                this.updateStatus('WebXR session stopped', 'warning');
                console.log('stopWebXR completed');
            }

            async initializeWebXR() {
                try {
                    this.updateStatus('Initializing WebXR session...', 'warning');
                    
                    // Check WebXR support first
                    if (!navigator.xr) {
                        throw new Error('WebXR not supported. Try Chrome/Edge with WebXR flags enabled.');
                    }

                    // Initialize WebGL context first
                    this.gl = this.canvas.getContext('webgl', { xrCompatible: true });
                    if (!this.gl) {
                        throw new Error('WebGL not supported');
                    }

                    // Try to make WebGL XR compatible
                    try {
                        await this.gl.makeXRCompatible();
                    } catch (error) {
                        console.warn('XR compatibility failed, trying without:', error);
                    }

                    // Try different session modes with better error handling
                    let sessionMode = 'inline';  // Start with inline mode (works without VR)
                    let sessionOptions = {
                        requiredFeatures: [],
                        optionalFeatures: ['local', 'local-floor', 'bounded-floor', 'hand-tracking']
                    };

                    // Try immersive VR first if available
                    try {
                        const vrSupported = await navigator.xr.isSessionSupported('immersive-vr');
                        if (vrSupported) {
                            sessionMode = 'immersive-vr';
                            sessionOptions.requiredFeatures = ['local'];
                            this.updateStatus('VR mode available - trying VR session...', 'warning');
                        }
                    } catch (vrError) {
                        console.log('VR not available, using inline mode');
                    }

                    // Request the session
                    try {
                        this.xrSession = await navigator.xr.requestSession(sessionMode, sessionOptions);
                    } catch (sessionError) {
                        // Fallback to basic inline session
                        sessionMode = 'inline';
                        this.xrSession = await navigator.xr.requestSession(sessionMode, {
                            optionalFeatures: ['local']
                        });
                    }

                    // Create XR layer
                    const layer = new XRWebGLLayer(this.xrSession, this.gl);
                    this.xrSession.updateRenderState({ baseLayer: layer });

                    // Get reference space with fallback and capture metadata
                    try {
                        this.xrRefSpace = await this.xrSession.requestReferenceSpace('local-floor');
                        this.xrSessionMetadata.referenceSpaceType = 'local-floor';
                        console.log('Using local-floor reference space');
                    } catch (refError) {
                        try {
                            this.xrRefSpace = await this.xrSession.requestReferenceSpace('local');
                            this.xrSessionMetadata.referenceSpaceType = 'local';
                            console.log('Using local reference space (fallback from local-floor)');
                            
                            // For local space, we may need to estimate headset height
                            this.xrSessionMetadata.headsetHeightM = 1.7; // Default estimate, will be updated if possible
                        } catch (localError) {
                        try {
                            this.xrRefSpace = await this.xrSession.requestReferenceSpace('viewer');
                                this.xrSessionMetadata.referenceSpaceType = 'viewer';
                                console.log('Using viewer reference space (fallback)');
                        } catch (viewerError) {
                            throw new Error('No suitable reference space available');
                            }
                        }
                    }
                    
                    // Log session metadata
                    console.log('XR Session Metadata captured:', this.xrSessionMetadata);
                    console.log('XR Path Log initialized with session ID:', this.xrSessionMetadata.sessionId);

                    // Start the render loop
                    this.xrSession.requestAnimationFrame((time, frame) => this.onXRFrame(time, frame));

                    // Session management
                    this.xrSession.addEventListener('end', () => this.onSessionEnd());
                    
                    // Set up input sources (controllers)
                    this.xrSession.addEventListener('inputsourceschange', (event) => {
                        this.setupControllers(event);
                    });
                    
                    this.isRunning = true;
                    this.sessionStartTime = Date.now();
                    this.canvas.style.display = 'block';
                    this.initBtn.textContent = 'Stop WebXR';
                    this.startAudioBtn.disabled = false;
                    this.exportBtn.disabled = false;
                    
                    this.updateStatus(`WebXR session started (${sessionMode} mode)`, 'success');
                    
                    // Show VR instructions if in VR mode
                    if (sessionMode === 'immersive-vr') {
                        document.getElementById('vr-instructions').style.display = 'block';
                    }

                } catch (error) {
                    this.updateStatus('WebXR failed: ' + error.message + ' - Try enabling WebXR flags in Chrome', 'error');
                    console.error('WebXR initialization error:', error);
                    
                    // Offer fallback mode
                    this.offerFallbackMode();
                }
            }

            offerFallbackMode() {
                this.updateStatus('WebXR unavailable - Click "Start Fallback Mode" for basic sensor simulation', 'warning');
                this.initBtn.textContent = 'Start Fallback Mode';
                this.initBtn.onclick = () => this.startFallbackMode();
            }

            startFallbackMode() {
                // Simulate sensor data using device orientation if available
                this.isRunning = true;
                this.sessionStartTime = Date.now();
                this.startAudioBtn.disabled = false;
                this.exportBtn.disabled = false;
                this.initBtn.textContent = 'Stop Fallback Mode';
                
                this.updateStatus('Fallback mode started - using device orientation sensors', 'success');
                
                // Try to use device orientation
                if ('DeviceOrientationEvent' in window) {
                    this.startDeviceOrientation();
                } else {
                    this.startSimulatedSensors();
                }
            }

            startDeviceOrientation() {
                window.addEventListener('deviceorientation', (event) => {
                    if (!this.isRunning) return;
                    
                    const timestamp = Date.now();
                    const imuReading = {
                        timestamp: timestamp,
                        position: {
                            x: '0.0000',
                            y: '0.0000', 
                            z: '0.0000'
                        },
                        orientation: {
                            x: ((event.beta || 0) / 180).toFixed(4),
                            y: ((event.gamma || 0) / 180).toFixed(4),
                            z: ((event.alpha || 0) / 360).toFixed(4),
                            w: '1.0000'
                        },
                        euler: {
                            roll: (event.gamma || 0).toFixed(2),
                            pitch: (event.beta || 0).toFixed(2),
                            yaw: (event.alpha || 0).toFixed(2)
                        }
                    };
                    
                    this.imuData.push(imuReading);
                    this.updateIMUDisplay(imuReading);
                });
            }

            startSimulatedSensors() {
                // Simulate sensor data for testing
                let angle = 0;
                const simulateData = () => {
                    if (!this.isRunning) return;
                    
                    angle += 0.02;
                    const timestamp = Date.now();
                    const imuReading = {
                        timestamp: timestamp,
                        position: {
                            x: (Math.sin(angle) * 0.1).toFixed(4),
                            y: (Math.cos(angle) * 0.05).toFixed(4),
                            z: '0.0000'
                        },
                        orientation: {
                            x: (Math.sin(angle * 0.5) * 0.1).toFixed(4),
                            y: (Math.cos(angle * 0.3) * 0.1).toFixed(4),
                            z: (Math.sin(angle * 0.7) * 0.1).toFixed(4),
                            w: '0.9950'
                        },
                        euler: {
                            roll: (Math.sin(angle) * 10).toFixed(2),
                            pitch: (Math.cos(angle) * 5).toFixed(2),
                            yaw: (angle * 10 % 360).toFixed(2)
                        }
                    };
                    
                    this.imuData.push(imuReading);
                    this.updateIMUDisplay(imuReading);
                    
                    setTimeout(simulateData, 50); // 20 FPS
                };
                
                simulateData();
            }

            onXRFrame(time, frame) {
                if (!this.isRunning) return;

                const currentTime = performance.now();
                
                // Handle VR controller input
                this.handleVRControllers(frame);
                
                // High-frequency comprehensive XR data collection (800Hz target)
                if (currentTime - this.lastIMUTime >= this.imuTargetInterval) {
                    const pose = frame.getViewerPose(this.xrRefSpace);
                    
                    if (pose) {
                        const timestamp = Date.now();
                        const position = pose.transform.position;
                        const orientation = pose.transform.orientation;
                        
                        // 1. Collect XR Pose Data (viewer head position and orientation)
                        const xrPoseEntry = `${timestamp},${position.x.toFixed(8)},${position.y.toFixed(8)},${position.z.toFixed(8)},${orientation.x.toFixed(8)},${orientation.y.toFixed(8)},${orientation.z.toFixed(8)},${orientation.w.toFixed(8)}`;
                        this.xrPoseData.push(xrPoseEntry);
                        
                        // 1a. Collect Comprehensive Path Log Data with tracking state
                        const trackingState = this.determineTrackingState(pose);
                        const pathLogEntry = `${this.xrSessionMetadata.sessionId},pose,${timestamp},${position.x.toFixed(8)},${position.y.toFixed(8)},${position.z.toFixed(8)},${orientation.x.toFixed(8)},${orientation.y.toFixed(8)},${orientation.z.toFixed(8)},${orientation.w.toFixed(8)},${trackingState}`;
                        this.xrPathLog.push(pathLogEntry);
                        
                        // Debug logging every 100 frames to verify data collection
                        if (this.xrPathLog.length % 100 === 0) {
                            console.log('XR Path Log progress:', {
                                entries: this.xrPathLog.length,
                                sessionId: this.xrSessionMetadata.sessionId,
                                trackingState: trackingState,
                                lastEntry: pathLogEntry
                            });
                        }
                        
                        // 2. Collect XR View Data (eye-specific transforms and projection matrices)
                        if (pose.views && pose.views.length > 0) {
                            for (let i = 0; i < pose.views.length; i++) {
                                const view = pose.views[i];
                                const eyeTransform = view.transform;
                                const eyePos = eyeTransform.position;
                                const eyeOrient = eyeTransform.orientation;
                                
                                // Eye view data entry
                                const viewEntry = `${timestamp},${i},${view.eye || 'none'},${eyePos.x.toFixed(8)},${eyePos.y.toFixed(8)},${eyePos.z.toFixed(8)},${eyeOrient.x.toFixed(8)},${eyeOrient.y.toFixed(8)},${eyeOrient.z.toFixed(8)},${eyeOrient.w.toFixed(8)}`;
                                this.xrViewData.push(viewEntry);
                                
                                // 3. Collect Projection Matrix Data
                                if (view.projectionMatrix) {
                                    const projMatrix = Array.from(view.projectionMatrix);
                                    const matrixEntry = `${timestamp},${i},${view.eye || 'none'},${projMatrix.map(v => v.toFixed(8)).join(',')}`;
                                    this.xrProjectionData.push(matrixEntry);
                                }
                            }
                        }
                        
                        // 4. Calculate accelerometer data (derived from position changes)
                        const dt = (currentTime - this.prevTime) / 1000; // Convert to seconds
                        let ax = 0, ay = 0, az = 0;
                        let gx = 0, gy = 0, gz = 0;
                        
                        if (dt > 0 && this.prevTime > 0) {
                            // Calculate velocity
                            const vx = (position.x - this.prevPosition.x) / dt;
                            const vy = (position.y - this.prevPosition.y) / dt;
                            const vz = (position.z - this.prevPosition.z) / dt;
                            
                            // Calculate acceleration
                            ax = (vx - this.prevVelocity.x) / dt;
                            ay = (vy - this.prevVelocity.y) / dt;
                            az = (vz - this.prevVelocity.z) / dt;
                            
                            // Calculate angular velocity (simplified)
                            const dqx = orientation.x - this.prevOrientation.x;
                            const dqy = orientation.y - this.prevOrientation.y;
                            const dqz = orientation.z - this.prevOrientation.z;
                            
                            gx = (dqx / dt) * 2; // Approximate gyroscope
                            gy = (dqy / dt) * 2;
                            gz = (dqz / dt) * 2;
                            
                            // Store velocity for next calculation
                            this.prevVelocity = { x: vx, y: vy, z: vz };
                        }
                        
                        // 5. Create high-frequency IMU data entry (derived motion data)
                        const imuEntry = `${timestamp},${ax.toFixed(8)},${ay.toFixed(8)},${az.toFixed(8)},${gx.toFixed(8)},${gy.toFixed(8)},${gz.toFixed(8)},${orientation.w.toFixed(8)},${orientation.x.toFixed(8)},${orientation.y.toFixed(8)},${orientation.z.toFixed(8)}`;
                        this.imuData.push(imuEntry);
                        
                        // Store previous values
                        this.prevPosition = { x: position.x, y: position.y, z: position.z };
                        this.prevOrientation = { x: orientation.x, y: orientation.y, z: orientation.z, w: orientation.w };
                        this.prevTime = currentTime;
                        
                        this.lastIMUTime = currentTime;
                        
                        // Update display (less frequently to avoid performance issues)
                        if (this.imuData.length % 50 === 0) {
                            this.updateIMUDisplay({
                                timestamp: timestamp,
                                position: { x: position.x.toFixed(4), y: position.y.toFixed(4), z: position.z.toFixed(4) },
                                orientation: { x: orientation.x.toFixed(4), y: orientation.y.toFixed(4), z: orientation.z.toFixed(4), w: orientation.w.toFixed(4) },
                                acceleration: { x: ax.toFixed(4), y: ay.toFixed(4), z: az.toFixed(4) },
                                gyroscope: { x: gx.toFixed(4), y: gy.toFixed(4), z: gz.toFixed(4) },
                                views: pose.views ? pose.views.length : 0
                            });
                        }
                    }
                }

                // Clear the canvas
                this.gl.clearColor(0.1, 0.1, 0.2, 1.0);
                this.gl.clear(this.gl.COLOR_BUFFER_BIT);

                // Continue the render loop
                if (this.isRunning) {
                    this.xrSession.requestAnimationFrame((time, frame) => this.onXRFrame(time, frame));
                }
            }

            // Determine XR tracking state from pose data
            determineTrackingState(pose) {
                try {
                    if (!pose || !pose.transform) {
                        console.log('Tracking state: lost (no pose or transform)');
                        return 'lost';
                    }
                    
                    // Check if position and orientation are valid
                    const pos = pose.transform.position;
                    const orient = pose.transform.orientation;
                    
                    if (!pos || !orient) {
                        console.log('Tracking state: lost (no position or orientation)');
                        return 'lost';
                    }
                    
                    // Check for invalid values (NaN, extreme values, etc.)
                    if (isNaN(pos.x) || isNaN(pos.y) || isNaN(pos.z) ||
                        isNaN(orient.x) || isNaN(orient.y) || isNaN(orient.z) || isNaN(orient.w)) {
                        console.log('Tracking state: lost (NaN values)');
                        return 'lost';
                    }
                    
                    // Check if quaternion is normalized (should be close to 1)
                    const quatMagnitude = Math.sqrt(orient.x * orient.x + orient.y * orient.y + orient.z * orient.z + orient.w * orient.w);
                    if (Math.abs(quatMagnitude - 1.0) > 0.1) {
                        console.log('Tracking state: limited (unnormalized quaternion:', quatMagnitude, ')');
                        return 'limited';
                    }
                    
                    // Check for extreme position values that might indicate tracking issues
                    const maxPos = 100; // 100 meters seems like a reasonable maximum
                    if (Math.abs(pos.x) > maxPos || Math.abs(pos.y) > maxPos || Math.abs(pos.z) > maxPos) {
                        console.log('Tracking state: limited (extreme position values)');
                        return 'limited';
                    }
                    
                    // Check if tracking was recently lost by comparing with previous frames
                    if (this.xrPathLog && this.xrPathLog.length > 0) {
                        const lastEntry = this.xrPathLog[this.xrPathLog.length - 1];
                        const lastParts = lastEntry.split(',');
                        if (lastParts.length >= 11) {
                            const lastPosX = parseFloat(lastParts[3]);
                            const lastPosY = parseFloat(lastParts[4]);
                            const lastPosZ = parseFloat(lastParts[5]);
                            
                            // Check for sudden jumps that might indicate tracking issues
                            const distance = Math.sqrt(
                                Math.pow(pos.x - lastPosX, 2) +
                                Math.pow(pos.y - lastPosY, 2) +
                                Math.pow(pos.z - lastPosZ, 2)
                            );
                            
                            // If position jumped more than 2 meters in one frame, it's likely limited tracking
                            if (distance > 2.0) {
                                console.log('Tracking state: limited (sudden jump:', distance.toFixed(3), 'm)');
                                return 'limited';
                            }
                        }
                    }
                    
                    // Log normal tracking every 500 frames to avoid spam
                    if (this.xrPathLog && this.xrPathLog.length % 500 === 0) {
                        console.log('Tracking state: normal (frame', this.xrPathLog.length, ')');
                    }
                    
                    return 'normal';
                } catch (error) {
                    console.error('Error determining tracking state:', error);
                    return 'lost';
                }
            }

            quaternionToEuler(q) {
                // Convert quaternion to Euler angles (in degrees)
                const sinr_cosp = 2 * (q.w * q.x + q.y * q.z);
                const cosr_cosp = 1 - 2 * (q.x * q.x + q.y * q.y);
                const roll = Math.atan2(sinr_cosp, cosr_cosp) * 180 / Math.PI;

                const sinp = 2 * (q.w * q.y - q.z * q.x);
                const pitch = Math.abs(sinp) >= 1 ? 
                    Math.sign(sinp) * Math.PI / 2 * 180 / Math.PI : 
                    Math.asin(sinp) * 180 / Math.PI;

                const siny_cosp = 2 * (q.w * q.z + q.x * q.y);
                const cosy_cosp = 1 - 2 * (q.y * q.y + q.z * q.z);
                const yaw = Math.atan2(siny_cosp, cosy_cosp) * 180 / Math.PI;

                return { roll, pitch, yaw };
            }

            // Generate unique session ID
            generateSessionId() {
                const chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';
                let result = '';
                for (let i = 0; i < 8; i++) {
                    result += chars.charAt(Math.floor(Math.random() * chars.length));
                }
                return result;
            }

            // Ensure audio samples are always properly initialized
            initializeAudioSamples() {
                console.log('Initializing audio samples structure...');
                this.rawAudioSamples = {
                    left: [],
                    right: []
                };
                console.log('Audio samples initialized:', this.rawAudioSamples);
            }

            // Validate audio samples structure
            validateAudioSamples() {
                if (!this.rawAudioSamples) {
                    console.warn('rawAudioSamples is null/undefined, reinitializing...');
                    this.initializeAudioSamples();
                    return false;
                }
                
                if (!this.rawAudioSamples.left) {
                    console.warn('rawAudioSamples.left is undefined, reinitializing...');
                    this.initializeAudioSamples();
                    return false;
                }
                
                if (!this.rawAudioSamples.right) {
                    console.warn('rawAudioSamples.right is undefined, reinitializing...');
                    this.initializeAudioSamples();
                    return false;
                }
                
                return true;
            }

            toggleAudio() {
                console.log('toggleAudio called');
                // Ensure audio samples are always properly initialized
                this.validateAudioSamples();
                
                if (this.audioContext && this.audioContext.state !== 'closed') {
                    this.stopAudio();
                } else {
                    this.initializeAudio();
                }
            }

            async initializeAudio() {
                try {
                    this.updateStatus('Requesting microphone access for 48kHz raw PCM recording...', 'warning');
                    
                    // Check if mediaDevices is available
                    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                        throw new Error('getUserMedia is not supported in this browser');
                    }
                    
                    // Request microphone access with fallback options
                    let stream;
                    try {
                        // Try stereo first
                        stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 48000,           // 48kHz
                                channelCount: 2,             // Stereo (dual channel)
                            echoCancellation: false,
                            noiseSuppression: false,
                            autoGainControl: false,
                            latency: 0.01               // Low latency
                        } 
                        });
                        console.log('Stereo audio access granted');
                    } catch (stereoError) {
                        console.warn('Stereo audio failed, trying mono:', stereoError.message);
                        // Fallback to mono
                        stream = await navigator.mediaDevices.getUserMedia({ 
                            audio: {
                                sampleRate: 48000,
                                channelCount: 1,             // Mono fallback
                                echoCancellation: false,
                                noiseSuppression: false,
                                autoGainControl: false,
                                latency: 0.01
                            } 
                        });
                        console.log('Mono audio access granted');
                        this.audioChannelCount = 1;
                    }
                    
                    if (!stream) {
                        throw new Error('Failed to get audio stream');
                    }
                    
                    // Validate stream has audio tracks
                    const audioTracks = stream.getAudioTracks();
                    if (audioTracks.length === 0) {
                        throw new Error('No audio tracks found in stream');
                    }
                    
                    console.log('Audio track info:', {
                        label: audioTracks[0].label,
                        enabled: audioTracks[0].enabled,
                        readyState: audioTracks[0].readyState,
                        settings: audioTracks[0].getSettings()
                    });
                    
                    // Create audio context with 48kHz sample rate
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 48000
                    });
                    
                    console.log('Actual audio context sample rate:', this.audioContext.sampleRate);
                    
                    this.microphone = this.audioContext.createMediaStreamSource(stream);
                    this.analyser = this.audioContext.createAnalyser();
                    
                    this.analyser.fftSize = 2048;
                    this.analyser.smoothingTimeConstant = 0.1; // Less smoothing for better response
                    
                    // Connect to analyser for visualization
                    this.microphone.connect(this.analyser);
                    
                    const bufferLength = this.analyser.frequencyBinCount;
                    this.dataArray = new Uint8Array(bufferLength);
                    
                    // Initialize raw PCM capture
                    await this.initializeRawAudioCapture(this.microphone);
                    
                    this.startAudioAnalysis();
                    this.startAudioBtn.textContent = 'Stop Audio';
                    
                    // Log the recording start time for chirp timing log
                    this.audioRecordingStartTime = Date.now();
                    const recordingStartTimeSeconds = this.audioRecordingStartTime / 1000;
                    this.chirpTimingLog.push(`Stereo Recording Started at ${recordingStartTimeSeconds}`);
                    console.log('Audio recording started, logged timestamp:', recordingStartTimeSeconds);
                    
                    this.updateStatus(`Raw PCM recording started at ${this.audioContext.sampleRate}Hz`, 'success');
                    
                } catch (error) {
                    console.error('Audio initialization failed:', error);
                    
                    // Provide specific error messages based on error type
                    let errorMessage = 'Failed to access microphone';
                    if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                        errorMessage = 'Microphone access denied. Please allow microphone permissions and refresh.';
                    } else if (error.name === 'NotFoundError' || error.name === 'DeviceNotFoundError') {
                        errorMessage = 'No microphone found. Please connect a microphone and refresh.';
                    } else if (error.name === 'NotSupportedError') {
                        errorMessage = 'Microphone not supported in this browser. Try Chrome, Firefox, or Safari.';
                    } else if (error.name === 'OverconstrainedError') {
                        errorMessage = 'Microphone constraints too strict. Trying basic access...';
                        // Try basic audio access
                        this.tryBasicAudioAccess();
                        return;
                    } else {
                        errorMessage = `Audio error: ${error.message}`;
                    }
                    
                    this.updateStatus(errorMessage, 'error');
                    
                    // Reset audio state on failure
                    this.audioContext = null;
                    this.microphone = null;
                    this.analyser = null;
                    this.startAudioBtn.disabled = false;
                    this.startAudioBtn.textContent = 'Start Audio Analysis';
                }
            }

            async tryBasicAudioAccess() {
                try {
                    console.log('Trying basic audio access...');
                    this.updateStatus('Trying basic microphone access...', 'warning');
                    
                    // Very basic audio request
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: true  // No constraints
                    });
                    
                    console.log('Basic audio access granted');
                    this.audioChannelCount = 1; // Assume mono for basic access
                    
                    // Create basic audio context
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    console.log('Basic audio context created with sample rate:', this.audioContext.sampleRate);
                    
                    this.microphone = this.audioContext.createMediaStreamSource(stream);
                    this.analyser = this.audioContext.createAnalyser();
                    this.analyser.fftSize = 2048;
                    this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
                    
                    this.microphone.connect(this.analyser);
                    
                    // Initialize basic raw audio capture
                    await this.initializeRawAudioCapture(this.microphone);
                    
                    this.updateStatus('Basic audio initialized successfully', 'success');
                    this.startAudioBtn.textContent = 'Stop Audio Analysis';
                    this.startDataCollection();
                    
                } catch (basicError) {
                    console.error('Basic audio access also failed:', basicError);
                    this.updateStatus('All audio access attempts failed. Check browser permissions.', 'error');
                    this.startAudioBtn.disabled = false;
                    this.startAudioBtn.textContent = 'Start Audio Analysis';
                }
            }

            async initializeRawAudioCapture(sourceNode) {
                try {
                    console.log('Initializing raw audio capture...');
                    // Ensure proper audio samples initialization
                    this.initializeAudioSamples();
                    
                    // Try AudioWorklet first (modern approach)
                    if (this.useAudioWorklet && this.audioContext.audioWorklet) {
                        console.log('Using AudioWorklet for raw PCM capture');
                        await this.setupAudioWorklet(sourceNode);
                    } else {
                        console.log('Using ScriptProcessorNode for raw PCM capture (fallback)');
                        this.setupScriptProcessor(sourceNode);
                    }
                    
                } catch (error) {
                    console.error('AudioWorklet failed, falling back to ScriptProcessor:', error);
                    this.useAudioWorklet = false;
                    this.setupScriptProcessor(sourceNode);
                }
            }

            async setupAudioWorklet(sourceNode) {
                // Load the AudioWorklet processor
                await this.audioContext.audioWorklet.addModule('./audio-capture-processor.js');
                
                // Create the AudioWorklet node
                this.audioWorkletNode = new AudioWorkletNode(this.audioContext, 'audio-capture-processor');
                
                // Handle messages from the processor
                this.audioWorkletNode.port.onmessage = (event) => {
                    const { type, samplesLeft, samplesRight, samples, sampleRate, channelCount, duration } = event.data;
                    
                    switch (type) {
                        case 'recordingStarted':
                            console.log('Raw PCM recording started via AudioWorklet:', channelCount || 1, 'channels');
                            this.audioChannelCount = channelCount || 1;
                            break;
                            
                        case 'audioChunk':
                            // Accumulate audio chunks (stereo)
                            this.validateAudioSamples(); // Ensure structure exists
                            
                            if (samplesLeft && samplesRight && samplesLeft.length > 0) {
                                this.rawAudioSamples.left.push(...samplesLeft);
                                this.rawAudioSamples.right.push(...samplesRight);
                                console.log('AudioWorklet stereo chunk received:', samplesLeft.length, 'samples per channel, total L/R:', 
                                    this.rawAudioSamples.left.length, '/', this.rawAudioSamples.right.length);
                            } else if (samples && samples.length > 0) {
                                // Fallback for mono
                                this.rawAudioSamples.left.push(...samples);
                                this.rawAudioSamples.right.push(...samples);
                                console.log('AudioWorklet mono chunk received:', samples.length, 'samples, duplicated to stereo');
                            } else {
                                console.warn('AudioWorklet chunk received with no valid samples');
                            }
                            break;
                            
                        case 'recordingStopped':
                            // Final samples (stereo)
                            this.validateAudioSamples(); // Ensure structure exists
                            
                            if (samplesLeft && samplesRight && samplesLeft.length > 0) {
                                this.rawAudioSamples.left.push(...samplesLeft);
                                this.rawAudioSamples.right.push(...samplesRight);
                                console.log(`Raw PCM recording completed: ${this.rawAudioSamples.left.length} samples per channel, ${duration.toFixed(2)}s`);
                            } else if (samples && samples.length > 0) {
                                // Fallback for mono
                                this.rawAudioSamples.left.push(...samples);
                                this.rawAudioSamples.right.push(...samples);
                                console.log(`Raw PCM recording completed (mono): ${samples.length} samples, ${duration.toFixed(2)}s`);
                            } else {
                                console.warn('AudioWorklet recording stopped with no valid samples');
                            }
                            break;
                    }
                };
                
                // Connect the audio chain: source -> worklet -> (nowhere, just processing)
                sourceNode.connect(this.audioWorkletNode);
                    
                    // Start recording
                this.audioWorkletNode.port.postMessage({
                    command: 'setSampleRate',
                    data: { 
                        sampleRate: this.audioContext.sampleRate,
                        channelCount: this.audioChannelCount
                    }
                });
                
                this.audioWorkletNode.port.postMessage({
                    command: 'start'
                });
            }

            setupScriptProcessor(sourceNode) {
                // Fallback to ScriptProcessorNode for older browsers
                const bufferSize = 4096;
                this.scriptProcessor = this.audioContext.createScriptProcessor(bufferSize, 1, 1);
                
                this.scriptProcessor.onaudioprocess = (event) => {
                    // Ensure audio samples are valid
                    this.validateAudioSamples();
                    
                    const inputBuffer = event.inputBuffer;
                    const leftChannel = inputBuffer.getChannelData(0);
                    const rightChannel = inputBuffer.numberOfChannels > 1 ? 
                        inputBuffer.getChannelData(1) : leftChannel; // Duplicate left if mono
                    
                    // Copy samples to our raw buffers
                    const oldLengthLeft = this.rawAudioSamples.left.length;
                    this.rawAudioSamples.left.push(...leftChannel);
                    this.rawAudioSamples.right.push(...rightChannel);
                    
                    // Log every 100th chunk to avoid spam
                    if (Math.floor(this.rawAudioSamples.left.length / 4096) !== Math.floor(oldLengthLeft / 4096)) {
                        console.log('ScriptProcessor stereo samples:', leftChannel.length, 'per channel, total L/R:', 
                            this.rawAudioSamples.left.length, '/', this.rawAudioSamples.right.length);
                    }
                };
                
                // Connect the audio chain
                sourceNode.connect(this.scriptProcessor);
                this.scriptProcessor.connect(this.audioContext.destination);
                
                console.log('ScriptProcessor setup completed for raw PCM capture');
            }

            startAudioAnalysis() {
                const canvas = document.getElementById('audio-visualizer');
                const ctx = canvas.getContext('2d');
                canvas.width = canvas.offsetWidth;
                canvas.height = canvas.offsetHeight;

                const analyzeAudio = () => {
                    if (!this.analyser) return;

                    this.analyser.getByteFrequencyData(this.dataArray);
                    
                    // Calculate audio metrics
                    const rms = this.calculateRMS(this.dataArray);
                    const peak = Math.max(...this.dataArray);
                    const centroid = this.calculateSpectralCentroid(this.dataArray);
                    
                    const audioReading = {
                        timestamp: Date.now(),
                        rms: rms.toFixed(2),
                        peak: peak,
                        spectralCentroid: centroid.toFixed(2),
                        frequencyData: Array.from(this.dataArray)
                    };
                    
                    this.audioData.push(audioReading);
                    this.updateAudioDisplay(audioReading);
                    this.drawAudioVisualization(ctx, canvas);
                    
                    requestAnimationFrame(analyzeAudio);
                };
                
                analyzeAudio();
            }

            calculateRMS(dataArray) {
                const sum = dataArray.reduce((acc, val) => acc + val * val, 0);
                return Math.sqrt(sum / dataArray.length);
            }

            calculateSpectralCentroid(dataArray) {
                let weightedSum = 0;
                let magnitudeSum = 0;
                
                for (let i = 0; i < dataArray.length; i++) {
                    weightedSum += i * dataArray[i];
                    magnitudeSum += dataArray[i];
                }
                
                return magnitudeSum > 0 ? weightedSum / magnitudeSum : 0;
            }

            drawAudioVisualization(ctx, canvas) {
                if (!this.dataArray) return;
                
                ctx.fillStyle = 'rgba(0, 0, 0, 0.3)';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                
                const barWidth = canvas.width / this.dataArray.length * 2;
                let x = 0;
                
                for (let i = 0; i < this.dataArray.length; i++) {
                    const barHeight = (this.dataArray[i] / 255) * canvas.height;
                    
                    const hue = (i / this.dataArray.length) * 360;
                    ctx.fillStyle = `hsl(${hue}, 70%, 60%)`;
                    ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                    
                    x += barWidth;
                }
            }

            stopAudio() {
                // Stop raw PCM capture
                if (this.audioWorkletNode) {
                    this.audioWorkletNode.port.postMessage({ command: 'stop' });
                    this.audioWorkletNode.disconnect();
                    this.audioWorkletNode = null;
                }
                
                if (this.scriptProcessor) {
                    this.scriptProcessor.disconnect();
                    this.scriptProcessor = null;
                }
                
                if (this.audioContext) {
                    this.audioContext.close();
                    this.audioContext = null;
                    this.microphone = null;
                    this.analyser = null;
                    this.dataArray = null;
                }
                
                this.startAudioBtn.textContent = 'Start Audio Analysis';
                
                // Validate and get audio samples
                this.validateAudioSamples();
                const leftSampleCount = this.rawAudioSamples.left.length;
                const rightSampleCount = this.rawAudioSamples.right.length;
                const duration = leftSampleCount / 48000; // Assuming 48kHz
                
                this.updateStatus(`Raw PCM stereo recording stopped: ${leftSampleCount} samples per channel (${duration.toFixed(2)}s)`, 'warning');
                console.log('Raw stereo audio samples captured - Left:', leftSampleCount, 'Right:', rightSampleCount);
            }

            updateIMUDisplay(reading) {
                const imuElement = document.getElementById('imu-data');
                imuElement.innerHTML = `
                    <strong>Timestamp:</strong> ${new Date(reading.timestamp).toLocaleTimeString()}<br>
                    <strong>Position (m):</strong><br>
                    &nbsp;&nbsp;X: ${reading.position.x}<br>
                    &nbsp;&nbsp;Y: ${reading.position.y}<br>
                    &nbsp;&nbsp;Z: ${reading.position.z}<br>
                    <strong>Acceleration (m/s²):</strong><br>
                    &nbsp;&nbsp;Ax: ${reading.acceleration ? reading.acceleration.x : '0.0000'}<br>
                    &nbsp;&nbsp;Ay: ${reading.acceleration ? reading.acceleration.y : '0.0000'}<br>
                    &nbsp;&nbsp;Az: ${reading.acceleration ? reading.acceleration.z : '0.0000'}<br>
                    <strong>Gyroscope (rad/s):</strong><br>
                    &nbsp;&nbsp;Gx: ${reading.gyroscope ? reading.gyroscope.x : '0.0000'}<br>
                    &nbsp;&nbsp;Gy: ${reading.gyroscope ? reading.gyroscope.y : '0.0000'}<br>
                    &nbsp;&nbsp;Gz: ${reading.gyroscope ? reading.gyroscope.z : '0.0000'}<br>
                    <strong>Quaternion:</strong><br>
                    &nbsp;&nbsp;W: ${reading.orientation.w}<br>
                    &nbsp;&nbsp;X: ${reading.orientation.x}<br>
                    &nbsp;&nbsp;Y: ${reading.orientation.y}<br>
                    &nbsp;&nbsp;Z: ${reading.orientation.z}<br>
                    <strong>XR Views:</strong> ${reading.views || 0} (L/R eyes)<br>
                    <strong>XR Pose samples:</strong> ${this.xrPoseData.length}<br>
                    <strong>XR View samples:</strong> ${this.xrViewData.length}<br>
                    <strong>XR Projection samples:</strong> ${this.xrProjectionData.length}<br>
                    <strong>Target rate:</strong> ${(this.xrPoseData.length / Math.max((Date.now() - this.sessionStartTime) / 1000, 1)).toFixed(1)} Hz
                `;
            }

            updateAudioDisplay(reading) {
                try {
                const audioElement = document.getElementById('audio-data');
                    const sampleRate = this.audioContext ? this.audioContext.sampleRate : 48000;
                    
                    // Validate and get audio samples
                    this.validateAudioSamples();
                    const leftSamples = this.rawAudioSamples.left.length;
                    const rightSamples = this.rawAudioSamples.right.length;
                    const duration = leftSamples / sampleRate;
                    
                    console.log('updateAudioDisplay debug:', {
                        leftSamples,
                        rightSamples,
                        duration,
                        rawAudioSamples: this.rawAudioSamples
                    });
                
                audioElement.innerHTML = `
                    <strong>Timestamp:</strong> ${new Date(reading.timestamp).toLocaleTimeString()}<br>
                    <strong>Sample Rate:</strong> ${sampleRate}Hz (Raw PCM)<br>
                    <strong>Channels:</strong> ${this.audioChannelCount || 2} (Stereo)<br>
                    <strong>RMS Level:</strong> ${reading.rms}<br>
                    <strong>Peak:</strong> ${reading.peak}<br>
                    <strong>Spectral Centroid:</strong> ${reading.spectralCentroid}<br>
                    <strong>Left Samples:</strong> ${leftSamples.toLocaleString()}<br>
                    <strong>Right Samples:</strong> ${rightSamples.toLocaleString()}<br>
                    <strong>Recording Duration:</strong> ${duration.toFixed(3)}s<br>
                    <strong>Capture Method:</strong> ${this.useAudioWorklet && this.audioWorkletNode ? 'AudioWorklet' : 'ScriptProcessor'}
                `;
                
                this.updateStats();
                } catch (error) {
                    console.error('updateAudioDisplay error:', error);
                    console.error('Error details:', {
                        message: error.message,
                        stack: error.stack,
                        rawAudioSamples: this.rawAudioSamples,
                        reading: reading
                    });
                    
                    // Fallback display
                    const audioElement = document.getElementById('audio-data');
                    if (audioElement) {
                        audioElement.innerHTML = `<strong>Audio Display Error:</strong> ${error.message}`;
                    }
                }
            }

            updateStats() {
                try {
                const statsElement = document.getElementById('stats-data');
                const duration = this.sessionStartTime ? 
                    ((Date.now() - this.sessionStartTime) / 1000).toFixed(1) : 0;
                
                    const dataRate = this.xrPoseData.length / Math.max(duration, 1);
                    
                    // Validate and get audio samples with error handling
                    this.validateAudioSamples();
                    const leftAudioSamples = this.rawAudioSamples.left.length;
                    const rightAudioSamples = this.rawAudioSamples.right.length;
                    const totalAudioSamples = leftAudioSamples + rightAudioSamples;
                    const audioSize = leftAudioSamples / (this.audioContext ? this.audioContext.sampleRate : 48000);
                    
                    console.log('updateStats debug:', {
                        leftAudioSamples,
                        rightAudioSamples,
                        totalAudioSamples,
                        audioSize,
                        rawAudioSamples: this.rawAudioSamples
                    });
                
                statsElement.innerHTML = `
                    <strong>Session Duration:</strong> ${duration}s<br>
                    <strong>XR Pose Samples:</strong> ${this.xrPoseData.length}<br>
                    <strong>XR Eye View Samples:</strong> ${this.xrViewData.length}<br>
                    <strong>XR Projection Matrices:</strong> ${this.xrProjectionData.length}<br>
                    <strong>XR Path Log Entries:</strong> ${this.xrPathLog ? this.xrPathLog.length : 0}<br>
                    <strong>Derived IMU Samples:</strong> ${this.imuData.length}<br>
                    <strong>Data Rate:</strong> ${dataRate.toFixed(1)} Hz (target: 800Hz)<br>
                    <strong>Raw Audio Samples:</strong> ${totalAudioSamples.toLocaleString()} (L:${leftAudioSamples.toLocaleString()}, R:${rightAudioSamples.toLocaleString()})<br>
                    <strong>Audio Duration:</strong> ${audioSize.toFixed(2)}s<br>
                    <strong>Audio Sample Rate:</strong> ${this.audioContext ? this.audioContext.sampleRate : 'N/A'}Hz<br>
                    <strong>Chirp Events:</strong> ${this.chirpTimingLog ? this.chirpTimingLog.length : 0}<br>
                    <strong>Estimated File Sizes:</strong><br>
                    &nbsp;&nbsp;XR Pose CSV: ~${(this.xrPoseData.length * 80 / 1024).toFixed(1)}KB<br>
                    &nbsp;&nbsp;XR Views CSV: ~${(this.xrViewData.length * 100 / 1024).toFixed(1)}KB<br>
                    &nbsp;&nbsp;XR Projection CSV: ~${(this.xrProjectionData.length * 200 / 1024).toFixed(1)}KB<br>
                    &nbsp;&nbsp;XR Path Log CSV: ~${((this.xrPathLog ? this.xrPathLog.length : 0) * 120 / 1024).toFixed(1)}KB<br>
                    &nbsp;&nbsp;IMU Motion CSV: ~${(this.imuData.length * 100 / 1024).toFixed(1)}KB<br>
                    &nbsp;&nbsp;Stereo Audio WAV: ~${((leftAudioSamples + rightAudioSamples) * 2 / 1024 / 1024).toFixed(1)}MB
                `;
                } catch (error) {
                    console.error('updateStats error:', error);
                    console.error('Error details:', {
                        message: error.message,
                        stack: error.stack,
                        rawAudioSamples: this.rawAudioSamples
                    });
                    
                    // Fallback display
                    const statsElement = document.getElementById('stats-data');
                    if (statsElement) {
                        statsElement.innerHTML = `<strong>Stats Error:</strong> ${error.message}`;
                    }
                }
            }

            // WAV File Encoder for Raw PCM Data (Stereo Support)
            encodeWAV(leftSamples, rightSamples = null, sampleRate = 48000) {
                // Determine if stereo or mono
                const numChannels = rightSamples ? 2 : 1;
                const samples = rightSamples ? { left: leftSamples, right: rightSamples } : { left: leftSamples };
                
                console.log('WAV Encoder input:', {
                    leftSamplesType: leftSamples.constructor.name,
                    leftSamplesLength: leftSamples.length,
                    rightSamplesLength: rightSamples ? rightSamples.length : 'N/A',
                    sampleRate: sampleRate,
                    numChannels: numChannels,
                    firstLeftSample: leftSamples[0],
                    firstRightSample: rightSamples ? rightSamples[0] : 'N/A'
                });
                
                if (!leftSamples || leftSamples.length === 0) {
                    throw new Error('No audio samples provided to WAV encoder');
                }
                
                if (!(leftSamples instanceof Float32Array) && !Array.isArray(leftSamples)) {
                    throw new Error('Left samples must be Float32Array or regular array');
                }
                
                if (rightSamples && (!(rightSamples instanceof Float32Array) && !Array.isArray(rightSamples))) {
                    throw new Error('Right samples must be Float32Array or regular array');
                }
                
                if (rightSamples && leftSamples.length !== rightSamples.length) {
                    throw new Error('Left and right channel samples must have same length');
                }
                
                const length = leftSamples.length;
                const dataSize = length * numChannels * 2; // 16-bit samples * channels
                const fileSize = 44 + dataSize;
                
                console.log('WAV file structure:', {
                    headerSize: 44,
                    dataSize: dataSize,
                    totalFileSize: fileSize,
                    expectedDuration: length / sampleRate
                });
                
                const buffer = new ArrayBuffer(fileSize);
                const view = new DataView(buffer);
                
                // Helper function to write strings
                const writeString = (offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };
                
                // WAV file header (44 bytes total)
                writeString(0, 'RIFF');                          // Chunk ID
                view.setUint32(4, fileSize - 8, true);           // Chunk size
                writeString(8, 'WAVE');                          // Format
                writeString(12, 'fmt ');                         // Subchunk1 ID
                view.setUint32(16, 16, true);                    // Subchunk1 size (16 for PCM)
                view.setUint16(20, 1, true);                     // Audio format (1 = PCM)
                view.setUint16(22, numChannels, true);           // Number of channels
                view.setUint32(24, sampleRate, true);            // Sample rate
                view.setUint32(28, sampleRate * numChannels * 2, true); // Byte rate
                view.setUint16(32, numChannels * 2, true);       // Block align
                view.setUint16(34, 16, true);                    // Bits per sample
                writeString(36, 'data');                         // Subchunk2 ID
                view.setUint32(40, dataSize, true);              // Subchunk2 size
                
                // Convert float samples to 16-bit PCM (interleaved for stereo)
                let offset = 44;
                let clippedSamples = 0;
                
                for (let i = 0; i < length; i++) {
                    // Left channel
                    let leftSample = leftSamples[i];
                    
                    // Handle NaN or undefined samples
                    if (isNaN(leftSample) || leftSample === undefined || leftSample === null) {
                        leftSample = 0;
                    }
                    
                    // Clamp sample to [-1, 1] range
                    if (leftSample > 1) {
                        leftSample = 1;
                        clippedSamples++;
                    } else if (leftSample < -1) {
                        leftSample = -1;
                        clippedSamples++;
                    }
                    
                    // Convert to 16-bit signed integer
                    const leftIntSample = leftSample < 0 ? leftSample * 0x8000 : leftSample * 0x7FFF;
                    view.setInt16(offset, Math.round(leftIntSample), true);
                    offset += 2;
                    
                    // Right channel (if stereo)
                    if (numChannels === 2) {
                        let rightSample = rightSamples[i];
                        
                        // Handle NaN or undefined samples
                        if (isNaN(rightSample) || rightSample === undefined || rightSample === null) {
                            rightSample = 0;
                        }
                        
                        // Clamp sample to [-1, 1] range
                        if (rightSample > 1) {
                            rightSample = 1;
                            clippedSamples++;
                        } else if (rightSample < -1) {
                            rightSample = -1;
                            clippedSamples++;
                        }
                        
                        // Convert to 16-bit signed integer
                        const rightIntSample = rightSample < 0 ? rightSample * 0x8000 : rightSample * 0x7FFF;
                        view.setInt16(offset, Math.round(rightIntSample), true);
                        offset += 2;
                    }
                }
                
                if (clippedSamples > 0) {
                    console.warn(`WAV encoder: ${clippedSamples} samples were clipped (${(clippedSamples/length*100).toFixed(2)}%)`);
                }
                
                console.log('WAV encoding complete:', {
                    bufferSize: buffer.byteLength,
                    expectedSize: fileSize,
                    clippedSamples: clippedSamples
                });
                
                return buffer;
            }



            async exportData() {
                console.log('exportData called, current state:', {
                    isRunning: this.isRunning,
                    imuDataLength: this.imuData.length,
                    audioChunksLength: this.audioChunks.length,
                    hasXRSession: !!this.xrSession
                });
                
                try {
                    this.updateStatus('Preparing data export...', 'warning');
                    
                    const timestamp = Date.now();
                    
                    // Create EST timestamp string
                    const now = new Date(timestamp);
                    const estOffset = -5; // EST is UTC-5 (adjust to -4 for EDT during daylight saving)
                    const estTime = new Date(now.getTime() + (estOffset * 60 * 60 * 1000));
                    
                    // Format: YYYY-MM-DD_HH-mm-ss_EST
                    const year = estTime.getUTCFullYear();
                    const month = String(estTime.getUTCMonth() + 1).padStart(2, '0');
                    const day = String(estTime.getUTCDate()).padStart(2, '0');
                    const hour = String(estTime.getUTCHours()).padStart(2, '0');
                    const minute = String(estTime.getUTCMinutes()).padStart(2, '0');
                    const second = String(estTime.getUTCSeconds()).padStart(2, '0');
                    
                    const dateStr = `${year}-${month}-${day}_${hour}-${minute}-${second}_EST`;
                    
                    let exportedFiles = [];
                    
                    // 1. Export XR Pose Data (Head position and orientation)
                    if (this.xrPoseData.length > 0) {
                        const csvHeader = 'UnixTime(ms),PosX,PosY,PosZ,OrientX,OrientY,OrientZ,OrientW\n';
                        const csvContent = csvHeader + this.xrPoseData.join('\n');
                        const filename = `xr_pose_data_${dateStr}.csv`;
                        
                        const csvBlob = new Blob([csvContent], { type: 'text/csv' });
                        await this.exportToGitHub(csvBlob, filename, 'XR viewer pose data (head position and orientation)');
                        this.downloadFile(csvBlob, filename);
                        exportedFiles.push(filename);
                    }
                    
                    // 2. Export XR View Data (Eye-specific transforms)
                    if (this.xrViewData.length > 0) {
                        const csvHeader = 'UnixTime(ms),ViewIndex,Eye,EyePosX,EyePosY,EyePosZ,EyeOrientX,EyeOrientY,EyeOrientZ,EyeOrientW\n';
                        const csvContent = csvHeader + this.xrViewData.join('\n');
                        const filename = `xr_eye_views_${dateStr}.csv`;
                        
                        const csvBlob = new Blob([csvContent], { type: 'text/csv' });
                        await this.exportToGitHub(csvBlob, filename, 'XR eye view transforms (left/right eye positions and orientations)');
                        this.downloadFile(csvBlob, filename);
                        exportedFiles.push(filename);
                    }
                    
                    // 3. Export XR Projection Matrix Data
                    if (this.xrProjectionData.length > 0) {
                        const csvHeader = 'UnixTime(ms),ViewIndex,Eye,M00,M01,M02,M03,M10,M11,M12,M13,M20,M21,M22,M23,M30,M31,M32,M33\n';
                        const csvContent = csvHeader + this.xrProjectionData.join('\n');
                        const filename = `xr_projection_matrices_${dateStr}.csv`;
                        
                        const csvBlob = new Blob([csvContent], { type: 'text/csv' });
                        await this.exportToGitHub(csvBlob, filename, 'XR projection matrices for stereo rendering');
                        this.downloadFile(csvBlob, filename);
                        exportedFiles.push(filename);
                    }
                    
                    // 4. Export IMU data as CSV (derived motion data)
                    if (this.imuData.length > 0) {
                        const csvHeader = 'UnixTime(ms),Ax,Ay,Az,Gx,Gy,Gz,QuatW,QuatX,QuatY,QuatZ\n';
                        const csvContent = csvHeader + this.imuData.join('\n');
                        const filename = `imu_derived_motion_${dateStr}.csv`;
                        
                        const csvBlob = new Blob([csvContent], { type: 'text/csv' });
                        await this.exportToGitHub(csvBlob, filename, 'Derived IMU motion data (calculated acceleration and gyroscope)');
                        this.downloadFile(csvBlob, filename);
                        exportedFiles.push(filename);
                    }
                    
                    // 5. Export Raw PCM Audio as Stereo WAV file
                    this.validateAudioSamples(); // Ensure structure exists
                    if (this.rawAudioSamples.left.length > 0) {
                        console.log('Exporting raw PCM stereo audio...', {
                            leftSampleCount: this.rawAudioSamples.left.length,
                            rightSampleCount: this.rawAudioSamples.right.length,
                            leftDataType: typeof this.rawAudioSamples.left,
                            rightDataType: typeof this.rawAudioSamples.right,
                            channels: this.audioChannelCount || 2
                        });
                        
                        const sampleRate = this.audioContext ? this.audioContext.sampleRate : 48000;
                        
                        // Convert to Float32Array if needed
                        let leftSamplesArray, rightSamplesArray;
                        
                        if (this.rawAudioSamples.left instanceof Float32Array) {
                            leftSamplesArray = this.rawAudioSamples.left;
                        } else if (Array.isArray(this.rawAudioSamples.left)) {
                            leftSamplesArray = new Float32Array(this.rawAudioSamples.left);
                        } else {
                            console.error('Invalid left audio samples format:', typeof this.rawAudioSamples.left);
                            this.updateStatus('Error: Invalid left audio samples format', 'error');
                            return;
                        }
                        
                        if (this.rawAudioSamples.right instanceof Float32Array) {
                            rightSamplesArray = this.rawAudioSamples.right;
                        } else if (Array.isArray(this.rawAudioSamples.right)) {
                            rightSamplesArray = new Float32Array(this.rawAudioSamples.right);
                        } else {
                            console.error('Invalid right audio samples format:', typeof this.rawAudioSamples.right);
                            this.updateStatus('Error: Invalid right audio samples format', 'error');
                            return;
                        }
                        
                        console.log('Converting to stereo WAV...', {
                            leftSamplesLength: leftSamplesArray.length,
                            rightSamplesLength: rightSamplesArray.length,
                            sampleRate: sampleRate,
                            duration: leftSamplesArray.length / sampleRate,
                            channels: 2
                        });
                        
                        const wavBuffer = this.encodeWAV(leftSamplesArray, rightSamplesArray, sampleRate);
                        console.log('Stereo WAV buffer created:', {
                            bufferSize: wavBuffer.byteLength,
                            bufferSizeMB: (wavBuffer.byteLength / 1024 / 1024).toFixed(2)
                        });
                        
                        const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
                        const filename = `raw_audio_stereo_${dateStr}.wav`;
                        
                        console.log('Created stereo WAV blob:', {
                            blobSize: wavBlob.size,
                            blobType: wavBlob.type,
                            filename: filename
                        });
                        
                        await this.exportToGitHub(wavBlob, filename, 'Raw PCM stereo audio data (WAV format)');
                        this.downloadFile(wavBlob, filename);
                        exportedFiles.push(filename);
                        
                        this.updateStatus(`Stereo WAV file exported: ${filename} (${(wavBlob.size / 1024 / 1024).toFixed(2)}MB)`, 'success');
                        
                        // 6. Export Chirp Timing Log as TXT file (same base name as audio file)
                        if (this.chirpTimingLog.length > 0) {
                            const txtContent = this.chirpTimingLog.join('\n');
                            const txtBlob = new Blob([txtContent], { type: 'text/plain' });
                            const txtFilename = filename.replace('.wav', '.txt'); // Same name as audio file but with .txt extension
                            
                            console.log('Exporting chirp timing log...', {
                                logEntries: this.chirpTimingLog.length,
                                txtFilename: txtFilename,
                                content: txtContent
                            });
                            
                            await this.exportToGitHub(txtBlob, txtFilename, 'Chirp timing log with recording start and playback events');
                            this.downloadFile(txtBlob, txtFilename);
                            exportedFiles.push(txtFilename);
                            
                            console.log(`Chirp timing log exported: ${txtFilename}`);
                        } else {
                            console.log('No chirp timing events to export');
                        }
                    } else {
                        console.warn('No raw audio samples to export');
                        this.updateStatus('No raw audio samples captured for export', 'warning');
                    }
                    
                    // 7. Export XR Path Log with comprehensive metadata
                    console.log('XR Path Log export check:', {
                        xrPathLogLength: this.xrPathLog ? this.xrPathLog.length : 'undefined',
                        sessionMetadata: this.xrSessionMetadata,
                        firstFewEntries: this.xrPathLog ? this.xrPathLog.slice(0, 3) : 'no data'
                    });
                    
                    if (this.xrPathLog && this.xrPathLog.length > 0) {
                        console.log('Exporting XR path log with metadata...', {
                            logEntries: this.xrPathLog.length,
                            sessionMetadata: this.xrSessionMetadata
                        });
                        
                        // Create CSV content with session metadata header
                        const metadataHeader = `# Session Metadata: ${this.xrSessionMetadata.sessionId},${this.xrSessionMetadata.referenceSpaceType},${this.xrSessionMetadata.units},${this.xrSessionMetadata.handedness},${this.xrSessionMetadata.upAxis},${this.xrSessionMetadata.forwardAxis},${this.xrSessionMetadata.headsetHeightM || ''}`;
                        const csvHeader = 'session_id,type,UnixTime(ms),PosX,PosY,PosZ,OrientX,OrientY,OrientZ,OrientW,trackingState';
                        const csvContent = metadataHeader + '\n' + csvHeader + '\n' + this.xrPathLog.join('\n');
                        
                        const csvBlob = new Blob([csvContent], { type: 'text/csv' });
                        const filename = `xr_path_log_${dateStr}.csv`;
                        
                        await this.exportToGitHub(csvBlob, filename, 'Comprehensive XR path log with tracking metadata');
                        this.downloadFile(csvBlob, filename);
                        exportedFiles.push(filename);
                        
                        console.log(`XR path log exported: ${filename}`);
                    } else {
                        console.log('No XR path data to export');
                    }
                    
                    // Export session metadata
                    const metadata = {
                        timestamp: timestamp,
                        sessionDuration: this.sessionStartTime ? (timestamp - this.sessionStartTime) / 1000 : 0,
                        imuSamples: this.imuData.length,
                        audioChunks: this.audioChunks.length,
                        sampleRate: this.audioContext ? this.audioContext.sampleRate : null,
                        exportedFiles: exportedFiles,
                        userAgent: navigator.userAgent,
                        webXRSession: this.xrSession ? 'active' : 'inactive'
                    };
                    
                    const metadataBlob = new Blob([JSON.stringify(metadata, null, 2)], { type: 'application/json' });
                    const metadataFilename = `session_metadata_${dateStr}.json`;
                    await this.exportToGitHub(metadataBlob, metadataFilename, 'Session metadata');
                    this.downloadFile(metadataBlob, metadataFilename);
                    
                    const totalSamples = this.xrPoseData.length + this.xrViewData.length + this.xrProjectionData.length + this.imuData.length;
                    this.updateStatus(`Comprehensive XR data exported: ${totalSamples} total samples across ${exportedFiles.length} files`, 'success');
                    
                } catch (error) {
                    this.updateStatus('Export failed: ' + error.message, 'error');
                    console.error('Export error:', error);
                }
            }

            async exportToGitHub(blob, filename, description) {
                try {
                    // GitHub Personal Access Token (user needs to set this)
                    const token = localStorage.getItem('github_token');
                    if (!token) {
                        console.warn('GitHub token not found. Set it with: localStorage.setItem("github_token", "your_token")');
                        this.updateStatus('GitHub token not configured - only local download available', 'warning');
                        return false;
                    }
                    
                    // Convert blob to base64
                    const base64Content = await this.blobToBase64(blob);
                    const base64Data = base64Content.split(',')[1]; // Remove data URL prefix
                    
                    const githubAPI = {
                        owner: 'wyjin603',
                        repo: 'webxr',
                        path: `data/${filename}`,
                        message: `Add ${description} - ${new Date().toISOString()}`,
                        content: base64Data
                    };
                    
                    const response = await fetch(`https://api.github.com/repos/${githubAPI.owner}/${githubAPI.repo}/contents/${githubAPI.path}`, {
                        method: 'PUT',
                        headers: {
                            'Authorization': `token ${token}`,
                            'Content-Type': 'application/json',
                            'Accept': 'application/vnd.github.v3+json'
                        },
                        body: JSON.stringify({
                            message: githubAPI.message,
                            content: githubAPI.content
                        })
                    });
                    
                    if (response.ok) {
                        console.log(`Successfully uploaded ${filename} to GitHub`);
                        this.updateStatus(`✅ ${filename} uploaded to GitHub successfully`, 'success');
                        return true;
                    } else {
                        const error = await response.json();
                        console.error('GitHub upload failed:', error);
                        this.updateStatus(`❌ GitHub upload failed: ${error.message || 'Unknown error'}`, 'error');
                        return false;
                    }
                    
                } catch (error) {
                    console.error('GitHub export error:', error);
                    return false;
                }
            }
            
            blobToBase64(blob) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onload = () => resolve(reader.result);
                    reader.onerror = reject;
                    reader.readAsDataURL(blob);
                });
            }

            downloadFile(blob, filename) {
                // VR-compatible download method
                if (navigator.xr && this.xrSession && this.xrSession.visibilityState === 'visible') {
                    // In VR mode, use a different approach
                    this.showVRDownloadNotification(filename);
                } else {
                    // Standard download for desktop/mobile
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = filename;
                    a.style.display = 'none';
                document.body.appendChild(a);
                a.click();
                    setTimeout(() => {
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
                    }, 100);
                }
            }
            
            showVRDownloadNotification(filename) {
                // Show notification in VR that file is being exported to GitHub
                this.updateStatus(`File ${filename} exported to GitHub (VR mode)`, 'success');
                
                // Optionally create a visual notification in 3D space
                // This would require WebXR rendering code
                console.log(`VR Export: ${filename} - Check GitHub repository for the file`);
            }

            toggleGitHubSetup() {
                const setupPanel = document.getElementById('github-setup');
                if (setupPanel.style.display === 'none') {
                    setupPanel.style.display = 'block';
                    this.githubSetupBtn.textContent = 'Hide GitHub Setup';
                } else {
                    setupPanel.style.display = 'none';
                    this.githubSetupBtn.textContent = 'Setup GitHub';
                }
            }

            saveGitHubToken() {
                const tokenInput = document.getElementById('github-token-input');
                const token = tokenInput.value.trim();
                
                if (!token) {
                    this.updateTokenStatus('Please enter a valid token', 'error');
                    return;
                }
                
                // Basic validation - GitHub tokens start with 'ghp_'
                if (!token.startsWith('ghp_') && !token.startsWith('github_pat_')) {
                    this.updateTokenStatus('Invalid token format. GitHub tokens start with "ghp_" or "github_pat_"', 'error');
                    return;
                }
                
                localStorage.setItem('github_token', token);
                tokenInput.value = '';
                this.updateTokenStatus('GitHub token saved successfully!', 'success');
                this.githubSetupBtn.textContent = '✅ GitHub Configured';
                
                // Test the token
                this.testGitHubToken();
            }

            async testGitHubToken() {
                try {
                    const token = localStorage.getItem('github_token');
                    const response = await fetch('https://api.github.com/user', {
                        headers: {
                            'Authorization': `token ${token}`,
                            'Accept': 'application/vnd.github.v3+json'
                        }
                    });
                    
                    if (response.ok) {
                        const user = await response.json();
                        this.updateTokenStatus(`Token valid! Connected as: ${user.login}`, 'success');
                    } else {
                        this.updateTokenStatus('Token is invalid or expired', 'error');
                        localStorage.removeItem('github_token');
                        this.githubSetupBtn.textContent = 'Setup GitHub';
                    }
                } catch (error) {
                    this.updateTokenStatus('Error testing token: ' + error.message, 'error');
                }
            }

            checkGitHubToken() {
                const token = localStorage.getItem('github_token');
                if (token) {
                    this.githubSetupBtn.textContent = '✅ GitHub Configured';
                    this.updateTokenStatus('GitHub token found. Testing...', 'warning');
                    this.testGitHubToken();
                } else {
                    this.updateTokenStatus('No GitHub token configured. Click "Setup GitHub" to configure.', 'warning');
                }
            }

            updateTokenStatus(message, type) {
                const statusElement = document.getElementById('token-status');
                statusElement.textContent = message;
                statusElement.className = `status ${type}`;
                statusElement.style.margin = '10px 0';
                statusElement.style.padding = '10px';
                statusElement.style.borderRadius = '6px';
                statusElement.style.textAlign = 'center';
                statusElement.style.fontWeight = 'bold';
            }

            // Chirp Audio System
            async initializeChirpAudio() {
                try {
                    console.log('Initializing chirp audio system...');
                    
                    // Create a separate audio context for chirp playback
                    this.chirpPlaybackContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 48000
                    });
                    
                    // Load both chirp audio files
                    this.chirpLoadPromise = this.loadChirpFile();
                    this.chirp2LoadPromise = this.loadChirp2File();
                    
                    console.log('Chirp audio system initialized');
                    
                } catch (error) {
                    console.error('Failed to initialize chirp audio system:', error);
                    this.updateStatus('Chirp audio system initialization failed: ' + error.message, 'warning');
                }
            }

            async loadChirpFile() {
                try {
                    console.log('Loading chirp audio file...');
                    
                    // Try to load the chirp file
                    const response = await fetch('./chirp_16_20khz_40ms.wav');
                    
                    if (!response.ok) {
                        throw new Error(`Failed to load chirp file: ${response.status} ${response.statusText}`);
                    }
                    
                    const arrayBuffer = await response.arrayBuffer();
                    this.chirpAudio = await this.chirpPlaybackContext.decodeAudioData(arrayBuffer);
                    
                    console.log('Chirp audio loaded successfully:', {
                        duration: this.chirpAudio.duration,
                        sampleRate: this.chirpAudio.sampleRate,
                        channels: this.chirpAudio.numberOfChannels
                    });
                    
                    this.updateStatus('Chirp audio loaded successfully', 'success');
                    
                } catch (error) {
                    console.warn('Could not load chirp file:', error);
                    this.updateStatus('Chirp file not found - please add chirp_16_20khz_40ms.wav to project', 'warning');
                    
                    // Generate a synthetic chirp as fallback
                    this.generateSyntheticChirp();
                }
            }

            async loadChirp2File() {
                try {
                    console.log('Loading second chirp audio file...');
                    
                    // Try to load the second chirp file
                    const response = await fetch('./chirp_8-23kHz_40ms.wav');
                    
                    if (!response.ok) {
                        throw new Error(`Failed to load second chirp file: ${response.status} ${response.statusText}`);
                    }
                    
                    const arrayBuffer = await response.arrayBuffer();
                    this.chirpAudio2 = await this.chirpPlaybackContext.decodeAudioData(arrayBuffer);
                    
                    console.log('Second chirp audio loaded successfully:', {
                        duration: this.chirpAudio2.duration,
                        sampleRate: this.chirpAudio2.sampleRate,
                        channels: this.chirpAudio2.numberOfChannels
                    });
                    
                    this.updateStatus('Second chirp audio loaded successfully', 'success');
                    
                } catch (error) {
                    console.warn('Could not load second chirp file:', error);
                    this.updateStatus('Second chirp file not found - please add chirp_8-23kHz_40ms.wav to project', 'warning');
                    
                    // Generate a synthetic chirp as fallback
                    this.generateSyntheticChirp2();
                }
            }

            generateSyntheticChirp() {
                try {
                    console.log('Generating synthetic chirp...');
                    
                    const sampleRate = 48000;
                    const duration = 0.04; // 40ms
                    const startFreq = 16000; // 16kHz
                    const endFreq = 20000;   // 20kHz
                    
                    const samples = Math.floor(sampleRate * duration);
                    this.chirpAudio = this.chirpPlaybackContext.createBuffer(1, samples, sampleRate);
                    
                    const channelData = this.chirpAudio.getChannelData(0);
                    
                    for (let i = 0; i < samples; i++) {
                        const t = i / sampleRate;
                        const progress = t / duration;
                        
                        // Linear frequency sweep from startFreq to endFreq
                        const frequency = startFreq + (endFreq - startFreq) * progress;
                        
                        // Generate the chirp signal with envelope
                        const phase = 2 * Math.PI * frequency * t;
                        const envelope = Math.sin(Math.PI * progress); // Bell-shaped envelope
                        
                        channelData[i] = envelope * Math.sin(phase) * 0.5; // 50% volume
                    }
                    
                    console.log('Synthetic chirp generated successfully');
                    this.updateStatus('Synthetic chirp generated (16-20kHz, 40ms)', 'success');
                    
                } catch (error) {
                    console.error('Failed to generate synthetic chirp:', error);
                    this.updateStatus('Failed to generate chirp audio', 'error');
                }
            }

            generateSyntheticChirp2() {
                try {
                    console.log('Generating synthetic chirp...');
                    
                    const sampleRate = 48000;
                    const duration = 0.04; // 40ms
                    const startFreq = 8000; // 8kHz
                    const endFreq = 23000;   // 23kHz
                    
                    const samples = Math.floor(sampleRate * duration);
                    this.chirpAudio2 = this.chirpPlaybackContext.createBuffer(1, samples, sampleRate);
                    
                    const channelData = this.chirpAudio2.getChannelData(0);
                    
                    for (let i = 0; i < samples; i++) {
                        const t = i / sampleRate;
                        const progress = t / duration;
                        
                        // Linear frequency sweep from startFreq to endFreq
                        const frequency = startFreq + (endFreq - startFreq) * progress;
                        
                        // Generate the chirp signal with envelope
                        const phase = 2 * Math.PI * frequency * t;
                        const envelope = Math.sin(Math.PI * progress); // Bell-shaped envelope
                        
                        channelData[i] = envelope * Math.sin(phase) * 0.5; // 50% volume
                    }
                    
                    console.log('Synthetic chirp generated successfully');
                    this.updateStatus('Synthetic chirp generated (8-23kHz, 40ms)', 'success');
                    
                } catch (error) {
                    console.error('Failed to generate synthetic chirp:', error);
                    this.updateStatus('Failed to generate chirp audio', 'error');
                }
            }

            async playChirp() {
                try {
                    console.log('Playing chirp...');
                    
                    // Ensure chirp is loaded
                    if (this.chirpLoadPromise) {
                        await this.chirpLoadPromise;
                    }
                    
                    if (!this.chirpAudio) {
                        throw new Error('Chirp audio not available');
                    }
                    
                    // Resume audio context if suspended (required for user interaction)
                    if (this.chirpPlaybackContext.state === 'suspended') {
                        await this.chirpPlaybackContext.resume();
                    }
                    
                    // Create audio source and connect to output
                    const source = this.chirpPlaybackContext.createBufferSource();
                    source.buffer = this.chirpAudio;
                    source.connect(this.chirpPlaybackContext.destination);
                    
                    // Log the chirp playback event with timestamp
                    const chirpTimestamp = Date.now();
                    const chirpTimestampSeconds = chirpTimestamp / 1000;
                    console.log('Chirp played at timestamp:', chirpTimestamp, 'seconds:', chirpTimestampSeconds);
                    
                    // Add to chirp timing log for TXT export
                    this.chirpTimingLog.push(`FMCW Linear 16-20kHz Playback Started at ${chirpTimestampSeconds}`);
                    
                    // Store chirp event in audio data for analysis
                    if (this.audioData) {
                        this.audioData.push({
                            timestamp: chirpTimestamp,
                            event: 'chirp_playback',
                            frequency_range: '16-20kHz',
                            duration: this.chirpAudio.duration * 1000 // in ms
                        });
                    }
                    
                    // Play the chirp
                    source.start();
                    
                    // Update UI
                    this.playChirpBtn.textContent = '🔊 Playing...';
                    this.playChirpBtn.disabled = true;
                    
                    // Re-enable button after chirp finishes
                    setTimeout(() => {
                        this.playChirpBtn.textContent = '🔊 Play Chirp (16-20kHz)';
                        this.playChirpBtn.disabled = false;
                    }, this.chirpAudio.duration * 1000 + 100);
                    
                    this.updateStatus(`Chirp played (${this.chirpAudio.duration * 1000}ms)`, 'success');
                    
                } catch (error) {
                    console.error('Failed to play chirp:', error);
                    this.updateStatus('Failed to play chirp: ' + error.message, 'error');
                    
                    // Re-enable button on error
                    this.playChirpBtn.textContent = '🔊 Play Chirp (16-20kHz)';
                    this.playChirpBtn.disabled = false;
                }
            }

            async playChirp2() {
                try {
                    console.log('Playing second chirp...');
                    
                    // Ensure chirp is loaded
                    if (this.chirp2LoadPromise) {
                        await this.chirp2LoadPromise;
                    }
                    
                    if (!this.chirpAudio2) {
                        throw new Error('Second chirp audio not available');
                    }
                    
                    // Resume audio context if suspended (required for user interaction)
                    if (this.chirpPlaybackContext.state === 'suspended') {
                        await this.chirpPlaybackContext.resume();
                    }
                    
                    // Create audio source and connect to output
                    const source = this.chirpPlaybackContext.createBufferSource();
                    source.buffer = this.chirpAudio2;
                    source.connect(this.chirpPlaybackContext.destination);
                    
                    // Log the chirp playback event with timestamp
                    const chirpTimestamp = Date.now();
                    const chirpTimestampSeconds = chirpTimestamp / 1000;
                    console.log('Second chirp played at timestamp:', chirpTimestamp, 'seconds:', chirpTimestampSeconds);
                    
                    // Add to chirp timing log for TXT export
                    this.chirpTimingLog.push(`FMCW Linear 8-23kHz Playback Started at ${chirpTimestampSeconds}`);
                    
                    // Store chirp event in audio data for analysis
                    if (this.audioData) {
                        this.audioData.push({
                            timestamp: chirpTimestamp,
                            event: 'chirp_playback_2',
                            frequency_range: '8-23kHz',
                            duration: this.chirpAudio2.duration * 1000 // in ms
                        });
                    }
                    
                    // Play the chirp
                    source.start();
                    
                    // Update UI
                    this.playChirp2Btn.textContent = '🔊 Playing...';
                    this.playChirp2Btn.disabled = true;
                    
                    // Re-enable button after chirp finishes
                    setTimeout(() => {
                        this.playChirp2Btn.textContent = '🔊 Play Chirp (8-23kHz)';
                        this.playChirp2Btn.disabled = false;
                    }, this.chirpAudio2.duration * 1000 + 100);
                    
                    this.updateStatus(`Second chirp played (${this.chirpAudio2.duration * 1000}ms)`, 'success');
                    
                } catch (error) {
                    console.error('Failed to play second chirp:', error);
                    this.updateStatus('Failed to play second chirp: ' + error.message, 'error');
                    
                    // Re-enable button on error
                    this.playChirp2Btn.textContent = '🔊 Play Chirp (8-23kHz)';
                    this.playChirp2Btn.disabled = false;
                }
            }

            // VR Controller and Input Handling
            setupControllers(event) {
                console.log('Input sources changed:', event);
                this.controllers = [];
                
                for (const inputSource of this.xrSession.inputSources) {
                    if (inputSource.targetRayMode === 'tracked-pointer') {
                        this.controllers.push(inputSource);
                        console.log('Added controller:', inputSource.handedness);
                    }
                }
                
                if (this.controllers.length > 0) {
                    this.updateStatus(`VR Controllers detected: ${this.controllers.length} - Use triggers to stop/export`, 'success');
                } else {
                    this.updateStatus('VR session active - Use keyboard: S=Stop, E=Export, A=Audio toggle', 'warning');
                }
            }

            handleVRControllers(frame) {
                if (!this.xrSession || this.controllers.length === 0) return;
                
                const currentTime = Date.now();
                
                for (let i = 0; i < this.controllers.length; i++) {
                    const controller = this.controllers[i];
                    
                    if (controller.gamepad) {
                        const gamepad = controller.gamepad;
                        
                        // Primary trigger (index 0) = Stop WebXR
                        if (gamepad.buttons[0] && gamepad.buttons[0].pressed) {
                            if (!this.vrButtonStates.stopPressed && 
                                currentTime - this.vrButtonStates.lastStopPress > 500) { // 500ms debounce
                                
                                this.vrButtonStates.stopPressed = true;
                                this.vrButtonStates.lastStopPress = currentTime;
                                
                                console.log('VR Controller: Stop WebXR triggered');
                                this.updateStatus('VR Controller: Stopping WebXR session...', 'warning');
                                this.stopWebXR();
                            }
                        } else {
                            this.vrButtonStates.stopPressed = false;
                        }
                        
                        // Secondary trigger or grip (index 1 or 4) = Export Data
                        const exportButton = gamepad.buttons[1] || gamepad.buttons[4];
                        if (exportButton && exportButton.pressed) {
                            if (!this.vrButtonStates.exportPressed && 
                                currentTime - this.vrButtonStates.lastExportPress > 1000) { // 1000ms debounce
                                
                                this.vrButtonStates.exportPressed = true;
                                this.vrButtonStates.lastExportPress = currentTime;
                                
                                console.log('VR Controller: Export Data triggered');
                                this.updateStatus('VR Controller: Exporting data...', 'warning');
                                this.exportData();
                            }
                        } else {
                            this.vrButtonStates.exportPressed = false;
                        }
                        
                        // Menu button (index 3) = Toggle Audio
                        if (gamepad.buttons[3] && gamepad.buttons[3].pressed) {
                            if (currentTime - this.vrButtonStates.lastAudioToggle > 1000) {
                                this.vrButtonStates.lastAudioToggle = currentTime;
                                console.log('VR Controller: Audio toggle triggered');
                                this.toggleAudio();
                            }
                        }
                        
                        // X/A button (index 2) = Play Chirp
                        if (gamepad.buttons[2] && gamepad.buttons[2].pressed) {
                            if (currentTime - (this.vrButtonStates.lastChirpPlay || 0) > 1000) {
                                this.vrButtonStates.lastChirpPlay = currentTime;
                                console.log('VR Controller: Chirp playback triggered');
                                this.playChirp();
                            }
                        }
                        
                        // Y/B button (index 5) = Play Second Chirp
                        if (gamepad.buttons[5] && gamepad.buttons[5].pressed) {
                            if (currentTime - (this.vrButtonStates.lastChirp2Play || 0) > 1000) {
                                this.vrButtonStates.lastChirp2Play = currentTime;
                                console.log('VR Controller: Second chirp playback triggered');
                                this.playChirp2();
                            }
                        }
                    }
                }
            }

            handleKeyboardInput(event) {
                console.log('Keyboard input:', event.key, 'XR session active:', !!this.xrSession);
                
                // Allow keyboard shortcuts even when not in XR session for debugging
                const currentTime = Date.now();
                
                switch(event.key.toLowerCase()) {
                    case 's':
                        if (currentTime - this.vrButtonStates.lastStopPress > 500) {
                            this.vrButtonStates.lastStopPress = currentTime;
                            console.log('Keyboard: Stop WebXR triggered');
                            this.updateStatus('Keyboard: Stopping WebXR session...', 'warning');
                            this.stopWebXR();
                            event.preventDefault();
                        }
                        break;
                        
                    case 'e':
                        if (currentTime - this.vrButtonStates.lastExportPress > 1000) {
                            this.vrButtonStates.lastExportPress = currentTime;
                            console.log('Keyboard: Export Data triggered');
                            this.updateStatus('Keyboard: Exporting data...', 'warning');
                            this.exportData();
                            event.preventDefault();
                        }
                        break;
                        
                    case 'a':
                        if (currentTime - (this.vrButtonStates.lastAudioToggle || 0) > 1000) {
                            this.vrButtonStates.lastAudioToggle = currentTime;
                            console.log('Keyboard: Audio toggle triggered');
                            this.toggleAudio();
                            event.preventDefault();
                        }
                        break;
                        
                    case 'c':
                        if (currentTime - (this.vrButtonStates.lastClear || 0) > 1000) {
                            this.vrButtonStates.lastClear = currentTime;
                            console.log('Keyboard: Clear data triggered');
                            this.clearData();
                            event.preventDefault();
                        }
                        break;
                        
                    case 'p':
                        if (currentTime - (this.vrButtonStates.lastChirpPlay || 0) > 1000) {
                            this.vrButtonStates.lastChirpPlay = currentTime;
                            console.log('Keyboard: Chirp playback triggered');
                            this.playChirp();
                            event.preventDefault();
                        }
                        break;
                        
                    case 'p2':
                    case '2':
                        if (currentTime - (this.vrButtonStates.lastChirp2Play || 0) > 1000) {
                            this.vrButtonStates.lastChirp2Play = currentTime;
                            console.log('Keyboard: Second chirp playback triggered');
                            this.playChirp2();
                            event.preventDefault();
                        }
                        break;
                }
            }

            clearData() {
                this.imuData = [];
                this.audioData = [];
                this.audioChunks = [];
                this.rawAudioBuffer = [];
                this.initializeAudioSamples(); // Clear raw PCM samples
                
                // Clear chirp timing log
                this.chirpTimingLog = [];
                this.audioRecordingStartTime = null;
                
                // Clear XR path log
                this.xrPathLog = [];
                
                // Clear comprehensive XR data
                this.xrPoseData = [];
                this.xrViewData = [];
                this.xrProjectionData = [];
                this.xrRawFrameData = [];
                
                this.sessionStartTime = Date.now();
                this.lastIMUTime = 0;
                this.prevPosition = { x: 0, y: 0, z: 0 };
                this.prevVelocity = { x: 0, y: 0, z: 0 };
                this.prevOrientation = { x: 0, y: 0, z: 0, w: 1 };
                this.prevTime = 0;
                
                // Reset chirp buttons
                this.playChirpBtn.textContent = '🔊 Play Chirp (16-20kHz)';
                this.playChirp2Btn.textContent = '🔊 Play Chirp (8-23kHz)';
                
                document.getElementById('imu-data').textContent = 'Data cleared - ready for comprehensive XR data collection';
                document.getElementById('audio-data').textContent = 'Raw PCM audio cleared - ready for 48kHz WAV recording';
                document.getElementById('stats-data').textContent = 'All XR and raw PCM data cleared';
                
                this.updateStatus('All XR and raw PCM data cleared - ready for comprehensive collection', 'warning');
            }

            onSessionEnd() {
                this.isRunning = false;
                this.canvas.style.display = 'none';
                this.initBtn.textContent = 'Initialize WebXR';
                this.startAudioBtn.disabled = true;
                this.exportBtn.disabled = true;
                this.stopAudio();
                
                // Hide VR instructions
                document.getElementById('vr-instructions').style.display = 'none';
                
                // Reset controller states
                this.controllers = [];
                this.vrButtonStates = {
                    stopPressed: false,
                    exportPressed: false,
                    lastStopPress: 0,
                    lastExportPress: 0
                };
                
                this.updateStatus('WebXR session ended', 'warning');
            }

            updateStatus(message, type) {
                this.status.textContent = message;
                this.status.className = `status ${type}`;
            }
        }

        // Initialize the app when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new WebXRSensorApp();
        });
    </script>
</body>
</html>
